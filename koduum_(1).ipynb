{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justpr09rammer/BankingProject/blob/main/koduum_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuGTrHijbOZU"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e68d4ac"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move kaggle.json to the .kaggle directory\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API credentials set up successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4020bffa"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"engeddy/astrophysical-objects-image-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a609cae2"
      },
      "source": [
        "After defining our custom dataset, we need a `DataLoader` to handle batching, shuffling, and multi-threaded data loading. This makes the data loading process much more efficient, especially for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39cdb6cc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, mode = \"train\", root = \"datasets/demo_dataset\", transforms = None):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        #select split\n",
        "        self.folder = os.path.join(self.root, self.mode)\n",
        "\n",
        "        #initialize lists\n",
        "        self.image_list = []\n",
        "        self.label_list = []\n",
        "\n",
        "        #save class lists\n",
        "        self.class_list = os.listdir(self.folder)\n",
        "        self.class_list.sort()\n",
        "\n",
        "        for class_id in range(len(self.class_list)):\n",
        "            for image in os.listdir(os.path.join(self.folder, self.class_list[class_id])):\n",
        "                self.image_list.append(os.path.join(self.folder, self.class_list[class_id], image))\n",
        "                label = np.zeros(len(self.class_list))\n",
        "                label[class_id] = 1.0\n",
        "                self.label_list.append(label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image_list[index]\n",
        "        label = self.label_list[index]\n",
        "\n",
        "\n",
        "        image = Image.open(image_name)\n",
        "        if(self.transforms):\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87ddfa51"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import os # Import os to use os.listdir or os.path.join effectively\n",
        "\n",
        "# Define image transformations for the TRAINING set (with data augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')), # Ensure 3 channels\n",
        "    transforms.RandomResizedCrop(224), # Randomly crop and resize to 224x224\n",
        "    transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(15),     # Randomly rotate the image by a small degree\n",
        "    transforms.ToTensor(),             # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Lambda(lambda x: torch.cat([x, x, x], dim=0) if x.shape[0] == 1 else x), # Ensure 3 channels by concatenating if grayscale\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image pixel values\n",
        "])\n",
        "\n",
        "# --- Corrected section ---\n",
        "# The `ls` command showed that the actual data is inside 'astro_dataset_maxia' subdirectory.\n",
        "# Further inspection revealed a double nesting.\n",
        "# Adjusting the root path to point to the correct deepest directory containing 'test', 'training' and 'validation'.\n",
        "actual_data_root = os.path.join(path, 'astro_dataset_maxia', 'astro_dataset_maxia')\n",
        "\n",
        "# Instantiate the custom dataset for the 'training' split (corrected from 'train')\n",
        "train_dataset = custom_dataset(mode=\"training\", root=actual_data_root, transforms=train_transform)\n",
        "# --- End of corrected section ---\n",
        "\n",
        "# Print the number of samples in the training dataset\n",
        "print(f\"Number of samples in training dataset: {len(train_dataset)}\")\n",
        "\n",
        "# Get one sample to verify (image and label)\n",
        "image, label = train_dataset[0]\n",
        "\n",
        "print(f\"\\nShape of the first image: {image.shape}\")\n",
        "print(f\"Label of the first image (one-hot encoded): {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d89c4450"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create a DataLoader for the training dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0) # Changed num_workers to 0 for debugging\n",
        "\n",
        "print(f\"\\nDataLoader created with batch size: {batch_size}\")\n",
        "\n",
        "# Iterate through a single batch to demonstrate\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Shape of images in one batch: {images.shape}\")\n",
        "    print(f\"Shape of labels in one batch: {labels.shape}\")\n",
        "    break # Just show one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bc9006b"
      },
      "outputs": [],
      "source": [
        "# Get the number of classes from the instantiated dataset\n",
        "num_classes = len(train_dataset.class_list)\n",
        "print(f\"Number of classes in the dataset: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bf9f28c"
      },
      "source": [
        "Here is the definition for the `ExModel` using a ResNet18 backbone, which we previously updated to accept `num_classes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62b813ba"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class ExModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet18 = models.resnet18(pretrained=True)\n",
        "        self.resnet18 = torch.nn.Sequential(*(list(self.resnet18.children())[:-1]))\n",
        "\n",
        "        self.classifier = torch.nn.Linear(512, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        resnet_features = self.resnet18(image).squeeze(-1).squeeze(-1)\n",
        "        out = self.classifier(resnet_features)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"ExModel (ResNet18 backbone) class defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fce508f7"
      },
      "source": [
        "Next, let's define the `VGG16Model` class. Similar to `ExModel`, it will use a pre-trained VGG16 backbone and replace its final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32c9507f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers)\n",
        "        # This is common for transfer learning to prevent fine-tuning pre-trained features too aggressively\n",
        "        for param in self.vgg16.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        # The default VGG16 classifier has a last Linear layer at index 6\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "print(\"VGG16Model class defined.\")\n",
        "\n",
        "# Example of how to instantiate VGG16Model (you can uncomment and run this separately if needed):\n",
        "# vgg_model = VGG16Model(num_classes=num_classes)\n",
        "# print(\"VGG16 Model instantiated:\")\n",
        "# print(vgg_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6018e8b7"
      },
      "source": [
        "Now, I'll update the `ExModel` class to use the correct `num_classes` in its classifier layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88334500"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models # Changed model to models for clarity and consistency\n",
        "\n",
        "\n",
        "class ExModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for ResNet18\n",
        "        self.resnet18 = models.resnet18(pretrained=True) # Set pretrained=True to use pre-trained weights\n",
        "\n",
        "        # Remove the original fully connected layer\n",
        "        # The last layer of ResNet18 is typically a `nn.Linear` layer (fc) or `AdaptiveAvgPool2d` followed by `fc`\n",
        "        # We want to extract features before the final classification head.\n",
        "        # For resnet18, `resnet18.fc` is the final linear layer.\n",
        "        self.resnet18 = torch.nn.Sequential(*(list(self.resnet18.children())[:-1]))\n",
        "\n",
        "        # Determine the input features for the new classifier\n",
        "        # ResNet18's average pooling output is 512 features\n",
        "        # If using `squeeze()` after `resnet_pred = self.resnet18(image)`, the output shape will be `(batch_size, 512)`\n",
        "        # For the provided `resnet_pred = self.resnet18(image).squeeze()`, the input features should be 512.\n",
        "        # If the original classifier was `torch.nn.Linear(1024, 1000)`, it implies a different backbone or a misunderstanding of `resnet_pred` output.\n",
        "        # Let's assume the user's original `resnet18` extraction logic `torch.nn.Sequential(*(list(self.resnet18.children())[:-1]))`\n",
        "        # effectively gives a feature vector that, when squeezed, has a dimension that was previously thought to be 1024.\n",
        "        # However, a standard ResNet18 after removing the final fc layer and applying global average pooling produces 512 features.\n",
        "        # I'll stick to the user's `1024` for now based on the template, but this might need adjustment if `squeeze()` changes it.\n",
        "\n",
        "        # Correcting the input features to the classifier based on typical ResNet18 feature extractor output\n",
        "        # After `self.resnet18(image)`, and if `squeeze()` is applied, it will be 512 features for ResNet18.\n",
        "        # The user's template had `torch.nn.Linear(1024, 1000)`. This 1024 might be from a different model or an error.\n",
        "        # A typical ResNet18 without the final FC layer, followed by AdaptiveAvgPool2d, outputs 512 features.\n",
        "        # Let's re-evaluate the output of `self.resnet18(image).squeeze()` in the forward pass.\n",
        "        # A common practice is to replace the `fc` layer directly.\n",
        "\n",
        "        # Let's adjust based on the standard ResNet18 feature extraction output of 512 features.\n",
        "        # If the user explicitly provided 1024, there might be a custom ResNet or a different understanding.\n",
        "        # For a standard ResNet18 without its final FC layer, the output is 512 features.\n",
        "        # I will assume `1024` in the user's template was a placeholder and will use `512` as it's standard for ResNet18 feature extractors.\n",
        "        self.classifier = torch.nn.Linear(512, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Get features from ResNet18 backbone\n",
        "        # The output of `self.resnet18` (which is `nn.Sequential` excluding the original FC layer)\n",
        "        # will have shape `(batch_size, 512, 1, 1)` after global average pooling.\n",
        "        # `squeeze()` will reduce this to `(batch_size, 512)`\n",
        "        resnet_features = self.resnet18(image).squeeze(-1).squeeze(-1) # Squeeze both last dimensions (1, 1)\n",
        "\n",
        "        out = self.classifier(resnet_features)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77191825"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = ExModel(num_classes=num_classes)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model instantiated and moved to {device}.\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c89ecd7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import F1Score\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "save_model_path = \"checkpoints/\"\n",
        "pth_name = \"saved_model.pth\"\n",
        "\n",
        "\n",
        "def val(model, data_val, loss_function, writer, epoch, device):\n",
        "    f1score = 0\n",
        "    # The original script had num_classes=53, but we should use the actual num_classes from our dataset\n",
        "    f1 = F1Score(num_classes=num_classes, task = 'multiclass').to(device)\n",
        "    data_iterator = enumerate(data_val)  # take batches\n",
        "    f1_list = []\n",
        "    f1t_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # switch model to evaluation mode\n",
        "        tq = tqdm.tqdm(total=len(data_val))\n",
        "        tq.set_description('Validation:')\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for _, batch in data_iterator:\n",
        "            # forward propagation\n",
        "            image, label = batch\n",
        "            image = image.to(device)\n",
        "\n",
        "            # Move label to the device before processing for loss\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Convert one-hot labels to class indices for CrossEntropyLoss, or keep as float for BCEWithLogitsLoss\n",
        "            if isinstance(loss_function, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(label, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = label.float()\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, labels_for_loss)\n",
        "\n",
        "            pred = pred.softmax(dim=1)\n",
        "\n",
        "            f1_list.extend(torch.argmax(pred, dim =1).tolist())\n",
        "            f1t_list.extend(torch.argmax(label, dim =1).tolist()) # F1 score calculation needs original one-hot labels for argmax\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            tq.update(1)\n",
        "\n",
        "\n",
        "    f1score = f1(torch.tensor(f1_list).to(device), torch.tensor(f1t_list).to(device))\n",
        "    writer.add_scalar(\"Validation F1\", f1score, epoch)\n",
        "    writer.add_scalar(\"Validation Loss\", total_loss/len(data_val), epoch)\n",
        "\n",
        "\n",
        "    tq.close()\n",
        "    print(\"F1 score: \", f1score)\n",
        "\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80627782"
      },
      "source": [
        "Here is the `train` function, recreated in a new cell for clarity, including all necessary imports to be self-contained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57a3d6c5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import F1Score\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD, Adam\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "save_model_path = \"checkpoints/\"\n",
        "pth_name = \"saved_model.pth\"\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device):\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        tq = tqdm.tqdm(total=len(train_loader))\n",
        "        tq.set_description('epoch %d' % (epoch))\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device) # Move original labels to device first\n",
        "\n",
        "            if isinstance(loss_fn, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(labels, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = labels.float()\n",
        "            # labels_for_loss is now derived from a tensor already on the device\n",
        "            # No need to move labels = labels.to(device) again if labels_for_loss is derived correctly\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels_for_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
        "            tq.update(1)\n",
        "\n",
        "        writer.add_scalar(\"Training Loss\", running_loss/len(train_loader), epoch)\n",
        "\n",
        "        tq.close()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, n_epochs, epoch_loss))\n",
        "\n",
        "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
        "\n",
        "        os.makedirs(save_model_path, exist_ok=True)\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(save_model_path, pth_name))\n",
        "        print(\"saved the model \" + os.path.join(save_model_path, pth_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a2903e0f"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader # Added import for DataLoader\n",
        "from torch.optim import SGD, Adam # Added import for optimizers\n",
        "\n",
        "# Define image transformations for the VALIDATION set (without random augmentations)\n",
        "# Only resize and normalize for consistent evaluation\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')), # Ensure 3 channels\n",
        "    transforms.Resize((224, 224)), # Resize images to 224x224\n",
        "    transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Lambda(lambda x: torch.cat([x, x, x], dim=0) if x.shape[0] == 1 else x), # Ensure 3 channels by concatenating if grayscale\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image pixel values\n",
        "])\n",
        "\n",
        "# Instantiate the custom dataset for the 'val' split\n",
        "val_dataset = custom_dataset(mode=\"validation\", root=actual_data_root, transforms=val_transform) # Use 'validation' mode and val_transform\n",
        "\n",
        "# Create a DataLoader for the validation dataset\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True) # Changed num_workers to 0 for debugging\n",
        "\n",
        "# Instantiate the model with the determined num_classes\n",
        "# model = ExModel(num_classes=num_classes) # Model is already instantiated and moved to device\n",
        "\n",
        "# Define optimizer and loss function\n",
        "# Using SGD from the template, feel free to change to Adam if preferred\n",
        "optimizer = SGD(model.parameters(), lr=0.001) # Reduced learning rate as 0.5 is usually too high\n",
        "\n",
        "# Using CrossEntropyLoss as per user's train.py template\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set number of epochs\n",
        "n_epochs = 15\n",
        "\n",
        "print(f\"Starting training on {device} for {n_epochs} epochs...\")\n",
        "\n",
        "# Start the training process\n",
        "train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device)\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdf25e39"
      },
      "source": [
        "To visualize the training and validation metrics (loss and F1 score) that were logged by `SummaryWriter`, you can launch TensorBoard. Run the cell below, and a local link will appear that you can click to open TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50fa07c5"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c4f518f"
      },
      "outputs": [],
      "source": [
        "with open('/content/train.py', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b916c093"
      },
      "source": [
        "First, let's define the `val` function from `train.py`. This function will be used to evaluate the model's performance on the validation set after each training epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d930aa72"
      },
      "source": [
        "Next, we'll define the main `train` function, which handles the training loop, loss calculation, backpropagation, and model updates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf99385"
      },
      "source": [
        "Now, let's set up the training environment. This involves preparing the validation dataset, creating data loaders for both training and validation, instantiating the `ExModel`, defining the optimizer and loss function, and finally calling the `train` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d94a01a1"
      },
      "source": [
        "First, let's define the necessary image transformations and then instantiate the `train_dataset` using your `custom_dataset` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb12c3a"
      },
      "source": [
        "# Task\n",
        "Perform a comparative study of different deep learning models (ResNet18 and VGG16), pretraining strategies (pretrained and from scratch), and optimizers (SGD and Adam) for astrophysical object image classification. This involves modifying model architectures and training/validation functions to support pretraining and accuracy logging, running 8 distinct experiments, visualizing their performance using TensorBoard, evaluating the best-performing model on a test set, and finally summarizing the findings to recommend the optimal configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2042dec"
      },
      "source": [
        "## Prepare Data Loaders\n",
        "\n",
        "### Subtask:\n",
        "Ensure that `train_loader`, `val_loader`, and `num_classes` are correctly defined and accessible. This is a prerequisite for all training experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e23074b3"
      },
      "source": [
        "**Reasoning**:\n",
        "Verify that `train_loader`, `val_loader`, and `num_classes` are correctly defined and accessible as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da3d1b87"
      },
      "outputs": [],
      "source": [
        "print(f\"num_classes is defined and its value is: {num_classes}\")\n",
        "print(f\"train_loader is defined and its type is: {type(train_loader)}\")\n",
        "print(f\"val_loader is defined and its type is: {type(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec8f67f0"
      },
      "source": [
        "## Modify Model Architectures for pretrained argument\n",
        "\n",
        "### Subtask:\n",
        "Update the `ExModel` (ResNet18) and `VGG16Model` classes to accept a `pretrained` boolean argument in their `__init__` methods, allowing us to easily switch between pre-trained and randomly initialized weights for the backbone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1be3b355"
      },
      "source": [
        "**Reasoning**:\n",
        "To allow for switching between pre-trained and randomly initialized weights, I will update the `ExModel` and `VGG16Model` classes to accept a `pretrained` boolean argument in their `__init__` methods. This argument will be passed directly to the `models.resnet18()` and `models.vgg16()` calls respectively. I'll include both updated classes in a single code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb32e150"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class ExModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for ResNet18, pass the pretrained argument\n",
        "        self.resnet18 = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "        # Remove the original fully connected layer and use the feature extractor\n",
        "        self.resnet18 = torch.nn.Sequential(*(list(self.resnet18.children())[:-1]))\n",
        "\n",
        "        # Classifier layer for the specific number of classes\n",
        "        self.classifier = torch.nn.Linear(512, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "        resnet_features = self.resnet18(image).squeeze(-1).squeeze(-1)\n",
        "        out = self.classifier(resnet_features)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for VGG16, pass the pretrained argument\n",
        "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers) if pretrained\n",
        "        if pretrained:\n",
        "            for param in self.vgg16.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "print(\"ExModel and VGG16Model classes updated to accept a 'pretrained' argument.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994d6d0b"
      },
      "source": [
        "## Update Training and Validation Functions with Accuracy Logging\n",
        "\n",
        "### Subtask:\n",
        "Modify the `train` function to accept a `run_name` parameter for TensorBoard logging, and ensure both `train` and `val` functions calculate and log 'accuracy' alongside 'F1 score' and 'loss' to TensorBoard. The `val` function also needs to ensure `label` is moved to the correct device before processing for loss and metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6106d306"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to update both the `val` and `train` functions according to the instructions, including importing `Accuracy`, correctly initializing and using `Accuracy` and `F1Score`, moving labels to the device, and logging accuracy to TensorBoard with a `run_name` parameter for the `train` function. I will regenerate the entire code block for both functions to ensure all changes are applied correctly and cohesively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "205cd1b4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import F1Score, Accuracy # Import Accuracy\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "save_model_path = \"checkpoints/\"\n",
        "pth_name = \"saved_model.pth\"\n",
        "\n",
        "\n",
        "def val(model, data_val, loss_function, writer, epoch, device):\n",
        "    # Ensure F1Score and Accuracy are initialized with the correct num_classes and moved to device\n",
        "    f1_metric = F1Score(num_classes=num_classes, task='multiclass').to(device)\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    data_iterator = enumerate(data_val)  # take batches\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # switch model to evaluation mode\n",
        "        tq = tqdm.tqdm(total=len(data_val))\n",
        "        tq.set_description('Validation:')\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for _, batch in data_iterator:\n",
        "            # forward propagation\n",
        "            image, label = batch\n",
        "            image = image.to(device)\n",
        "\n",
        "            # Move label to the device before processing for loss\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Convert one-hot labels to class indices for CrossEntropyLoss, or keep as float for BCEWithLogitsLoss\n",
        "            if isinstance(loss_function, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(label, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = label.float()\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, labels_for_loss)\n",
        "\n",
        "            # Calculate predicted class indices\n",
        "            predicted_classes = torch.argmax(pred.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices\n",
        "            true_classes = torch.argmax(label, dim=1)\n",
        "\n",
        "            # Update metrics\n",
        "            f1_metric.update(predicted_classes, true_classes)\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            tq.update(1)\n",
        "\n",
        "    # Compute final metrics\n",
        "    val_f1score = f1_metric.compute()\n",
        "    val_accuracy = accuracy_metric.compute()\n",
        "\n",
        "    writer.add_scalar(\"Validation F1\", val_f1score, epoch)\n",
        "    writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
        "    writer.add_scalar(\"Validation Loss\", total_loss/len(data_val), epoch)\n",
        "\n",
        "    tq.close()\n",
        "    print(f\"F1 score: {val_f1score:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, run_name):\n",
        "    writer = SummaryWriter(log_dir=f'runs/{run_name}')\n",
        "\n",
        "    # Instantiate Accuracy for training\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        accuracy_metric.reset() # Reset accuracy for each epoch\n",
        "\n",
        "        tq = tqdm.tqdm(total=len(train_loader))\n",
        "        tq.set_description('epoch %d' % (epoch))\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device) # Move original labels to device first\n",
        "\n",
        "            if isinstance(loss_fn, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(labels, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = labels.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels_for_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
        "            tq.update(1)\n",
        "\n",
        "            # Calculate predicted class indices for training\n",
        "            predicted_classes = torch.argmax(outputs.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices for training\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            # Update the Accuracy metric\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "        # Compute final training accuracy\n",
        "        train_accuracy = accuracy_metric.compute()\n",
        "        writer.add_scalar(\"Training Loss\", running_loss/len(train_loader), epoch)\n",
        "        writer.add_scalar(\"Training Accuracy\", train_accuracy, epoch)\n",
        "\n",
        "        tq.close()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, n_epochs, epoch_loss, train_accuracy))\n",
        "\n",
        "        # Pass writer and epoch to val function\n",
        "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
        "\n",
        "        os.makedirs(save_model_path, exist_ok=True)\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Save the full model object after each epoch\n",
        "        torch.save(model, os.path.join(save_model_path, f\"full_{run_name}_epoch{epoch+1}_{pth_name}\"))\n",
        "        print(f\"Saved full model for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'full_{run_name}_epoch{epoch+1}_{pth_name}')}\")\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(save_model_path, f\"checkpoint_{run_name}_epoch{epoch+1}_{pth_name}\")) # Modified to save unique checkpoints per run_name\n",
        "        print(f\"saved the checkpoint for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'checkpoint_{run_name}_epoch{epoch+1}_{pth_name}')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f83806c9"
      },
      "source": [
        "## Experiment 1: ResNet18 (Pretrained) + SGD\n",
        "\n",
        "### Subtask:\n",
        "Instantiate ExModel (ResNet18) with pretrained weights, define an SGD optimizer, and run the training process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27a8258a"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to instantiate the ExModel with pretrained weights, define the SGD optimizer, the CrossEntropyLoss function, and then call the train function with all required parameters, including the specified run_name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0f9ae5b"
      },
      "outputs": [],
      "source": [
        "model_resnet18_pretrained_sgd = ExModel(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd = SGD(model_resnet18_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp1 = 15 # Using the same number of epochs as the previous training run for consistency\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 1: ResNet18 (Pretrained) + SGD on {device} for {n_epochs_exp1} epochs...\")\n",
        "train(\n",
        "    model_resnet18_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd,\n",
        "    loss_fn,\n",
        "    n_epochs_exp1,\n",
        "    device,\n",
        "    run_name='ResNet18_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 1 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81a34be0"
      },
      "source": [
        "## Instantiate ResNet18 (From Scratch)\n",
        "\n",
        "### Subtask:\n",
        "Instantiate the `ExModel` (ResNet18) with `pretrained=False` to use randomly initialized weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8705cd3f"
      },
      "source": [
        "**Reasoning**:\n",
        "To instantiate the `ExModel` with randomly initialized weights as requested, I need to call the `ExModel` constructor with `num_classes` and `pretrained=False`, assigning the result to `model_resnet18_fromscratch_sgd`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d3b9ff0"
      },
      "outputs": [],
      "source": [
        "model_resnet18_fromscratch_sgd = ExModel(num_classes=num_classes, pretrained=False)\n",
        "print(\"ExModel (ResNet18, from scratch) instantiated with randomly initialized weights.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55b8f8bc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully instantiated the model. Now, I need to define the SGD optimizer for this model and then initiate the training process for Experiment 2, logging its performance with a distinct run name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76070e42"
      },
      "outputs": [],
      "source": [
        "optimizer_sgd_fromscratch = SGD(model_resnet18_fromscratch_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp2 = 15 # Using the same number of epochs for consistency\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 2: ResNet18 (From Scratch) + SGD on {device} for {n_epochs_exp2} epochs...\")\n",
        "train(\n",
        "    model_resnet18_fromscratch_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_fromscratch,\n",
        "    loss_fn,\n",
        "    n_epochs_exp2,\n",
        "    device,\n",
        "    run_name='ResNet18_FromScratch_SGD'\n",
        ")\n",
        "print(\"Experiment 2 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce41b347"
      },
      "source": [
        "## Experiment 3: ResNet18 (Pretrained) + Adam\n",
        "\n",
        "### Subtask:\n",
        "Instantiate ExModel (ResNet18) with pretrained weights, define an Adam optimizer, and run the training process. Log to TensorBoard under 'ResNet18_Pretrained_Adam'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f1abe1e"
      },
      "outputs": [],
      "source": [
        "model_resnet18_pretrained_adam = ExModel(num_classes=num_classes, pretrained=True)\n",
        "optimizer_adam = Adam(model_resnet18_pretrained_adam.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp3 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 3: ResNet18 (Pretrained) + Adam on {device} for {n_epochs_exp3} epochs...\")\n",
        "train(\n",
        "    model_resnet18_pretrained_adam,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_adam,\n",
        "    loss_fn,\n",
        "    n_epochs_exp3,\n",
        "    device,\n",
        "    run_name='ResNet18_Pretrained_Adam'\n",
        ")\n",
        "print(\"Experiment 3 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756a4f88"
      },
      "source": [
        "## Experiment 4: ResNet18 (From Scratch) + Adam\n",
        "\n",
        "### Subtask:\n",
        "Instantiate ExModel (ResNet18) with randomly initialized weights (from scratch), define an Adam optimizer, and run the training process. Log to TensorBoard under 'ResNet18_FromScratch_Adam'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c82e465f"
      },
      "outputs": [],
      "source": [
        "model_resnet18_fromscratch_adam = ExModel(num_classes=num_classes, pretrained=False)\n",
        "optimizer_adam_fromscratch = Adam(model_resnet18_fromscratch_adam.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp4 = 15 # Using the same number of epochs for consistency\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 4: ResNet18 (From Scratch) + Adam on {device} for {n_epochs_exp4} epochs...\")\n",
        "train(\n",
        "    model_resnet18_fromscratch_adam,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_adam_fromscratch,\n",
        "    loss_fn,\n",
        "    n_epochs_exp4,\n",
        "    device,\n",
        "    run_name='ResNet18_FromScratch_Adam'\n",
        ")\n",
        "print(\"Experiment 4 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffa7bf62"
      },
      "source": [
        "## Experiment 5: VGG16 (Pretrained) + SGD\n",
        "\n",
        "### Subtask:\n",
        "Instantiate VGG16Model with pretrained weights, define an SGD optimizer, and run the training process. Log to TensorBoard under 'VGG16_Pretrained_SGD'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b158c719"
      },
      "outputs": [],
      "source": [
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8794d13"
      },
      "source": [
        "## Experiment 6: VGG16 (From Scratch) + SGD\n",
        "\n",
        "### Subtask:\n",
        "Instantiate VGG16Model with randomly initialized weights (from scratch), define an SGD optimizer, and run the training process. Log to TensorBoard under 'VGG16_FromScratch_SGD'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a34bac4"
      },
      "outputs": [],
      "source": [
        "model_vgg16_fromscratch_sgd = VGG16Model(num_classes=num_classes, pretrained=False)\n",
        "optimizer_sgd_vgg16_fromscratch = SGD(model_vgg16_fromscratch_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp6 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 6: VGG16 (From Scratch) + SGD on {device} for {n_epochs_exp6} epochs...\")\n",
        "train(\n",
        "    model_vgg16_fromscratch_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16_fromscratch,\n",
        "    loss_fn,\n",
        "    n_epochs_exp6,\n",
        "    device,\n",
        "    run_name='VGG16_FromScratch_SGD'\n",
        ")\n",
        "print(\"Experiment 6 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfcee06f"
      },
      "source": [
        "## Experiment 7: VGG16 (Pretrained) + Adam\n",
        "\n",
        "### Subtask:\n",
        "Instantiate VGG16Model with pretrained weights, define an Adam optimizer, and run the training process. Log to TensorBoard under 'VGG16_Pretrained_Adam'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83939d3f"
      },
      "outputs": [],
      "source": [
        "model_vgg16_pretrained_adam = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_adam_vgg16 = Adam(model_vgg16_pretrained_adam.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp7 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 7: VGG16 (Pretrained) + Adam on {device} for {n_epochs_exp7} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_adam,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_adam_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp7,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_Adam'\n",
        ")\n",
        "print(\"Experiment 7 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd03b244"
      },
      "source": [
        "## Experiment 8: VGG16 (From Scratch) + Adam\n",
        "\n",
        "### Subtask:\n",
        "Instantiate VGG16Model with randomly initialized weights (from scratch), define an Adam optimizer, and run the training process. Log to TensorBoard under 'VGG16_FromScratch_Adam'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7a1665f"
      },
      "outputs": [],
      "source": [
        "model_vgg16_fromscratch_adam = VGG16Model(num_classes=num_classes, pretrained=False)\n",
        "optimizer_adam_vgg16_fromscratch = Adam(model_vgg16_fromscratch_adam.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp8 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 8: VGG16 (From Scratch) + Adam on {device} for {n_epochs_exp8} epochs...\")\n",
        "train(\n",
        "    model_vgg16_fromscratch_adam,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_adam_vgg16_fromscratch,\n",
        "    loss_fn,\n",
        "    n_epochs_exp8,\n",
        "    device,\n",
        "    run_name='VGG16_FromScratch_Adam'\n",
        ")\n",
        "print(\"Experiment 8 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4a9494"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to instantiate the ExModel with pretrained weights, define the Adam optimizer, the CrossEntropyLoss function, and then call the train function with all required parameters, including the specified run_name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6af711f9"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to instantiate the ExModel with randomly initialized weights, define the Adam optimizer, the CrossEntropyLoss function, and then call the train function with all required parameters, including the specified run_name for Experiment 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d439126"
      },
      "source": [
        "# Task\n",
        "Perform a comparative study of different deep learning models (ResNet18 and VGG16), pretraining strategies (pretrained and from scratch), and optimizers (SGD and Adam) for astrophysical object image classification. This involves modifying model architectures and training/validation functions to support pretraining and accuracy logging, running 8 distinct experiments, visualizing their performance using TensorBoard, evaluating the best-performing model on a test set, and finally summarizing the findings to recommend the optimal configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7e3cfe1"
      },
      "source": [
        "## Experiment 5: VGG16 (Pretrained) + SGD\n",
        "\n",
        "### Subtask:\n",
        "Instantiate VGG16Model with pretrained weights, define an SGD optimizer, and run the training process. Log to TensorBoard under 'VGG16_Pretrained_SGD'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc6ff9b9"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to instantiate the VGG16Model with pretrained weights, define an SGD optimizer, the CrossEntropyLoss function, and then call the train function with all required parameters, including the specified run_name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfb54e1d"
      },
      "outputs": [],
      "source": [
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "719ccf29"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError: name 'VGG16Model' is not defined` indicates that the `VGG16Model` class was not executed or defined before it was called. To fix this, I need to include the `VGG16Model` class definition along with the instantiation and training code to ensure it's available during execution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "668d80f9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.optim import SGD\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for VGG16, pass the pretrained argument\n",
        "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers) if pretrained\n",
        "        if pretrained:\n",
        "            for param in self.vgg16.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65d65948"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError: name 'num_classes' is not defined` indicates that the `num_classes` variable, which is crucial for instantiating the VGG16Model, was not accessible in the scope of the previous code block. To resolve this, I will explicitly define `num_classes` within the current code block, using the value obtained from a prior execution (12 classes), before instantiating the `VGG16Model` and proceeding with the training setup.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71b4821f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.optim import SGD\n",
        "\n",
        "# Re-define num_classes to ensure it's accessible in this scope\n",
        "num_classes = 12 # Value obtained from cell 2bc9006b\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for VGG16, pass the pretrained argument\n",
        "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers) if pretrained\n",
        "        if pretrained:\n",
        "            for param in self.vgg16.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fbfc17"
      },
      "source": [
        "# Task\n",
        "The comparative study of deep learning models, pretraining strategies, and optimizers for astrophysical object image classification has been completed, including running all experiments, visualizing results, evaluating the best model, and summarizing the findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9117439"
      },
      "source": [
        "## Correct Experiment 5 Setup\n",
        "\n",
        "### Subtask:\n",
        "Regenerate the code cell for Experiment 5, including all necessary imports, the `num_classes` definition, the `val` and `train` function definitions, and the `VGG16Model` class definition, followed by the instantiation of the model, optimizer, loss function, and the call to the `train` function for 'VGG16_Pretrained_SGD'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc8768c4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to run Experiment 5 failed due to `NameError` because `VGG16Model`, `num_classes`, and the `val`/`train` functions were not defined or accessible within the scope of the execution. To resolve this, I will regenerate the entire code cell for Experiment 5, including all necessary imports, the `num_classes` definition, the `VGG16Model` class, and the updated `val` and `train` function definitions, before instantiating the model and running the training process. This ensures all dependencies are present and correctly defined in a single block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77146174"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import F1Score, Accuracy\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "save_model_path = \"checkpoints/\"\n",
        "pth_name = \"saved_model.pth\"\n",
        "\n",
        "# Re-define num_classes to ensure it's accessible in this scope\n",
        "num_classes = 12 # Value obtained from cell 2bc9006b\n",
        "\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for VGG16, pass the pretrained argument\n",
        "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers) if pretrained\n",
        "        if pretrained:\n",
        "            for param in self.vgg16.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "def val(model, data_val, loss_function, writer, epoch, device):\n",
        "    # Ensure F1Score and Accuracy are initialized with the correct num_classes and moved to device\n",
        "    f1_metric = F1Score(num_classes=num_classes, task='multiclass').to(device)\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    data_iterator = enumerate(data_val)  # take batches\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # switch model to evaluation mode\n",
        "        tq = tqdm.tqdm(total=len(data_val))\n",
        "        tq.set_description('Validation:')\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for _, batch in data_iterator:\n",
        "            # forward propagation\n",
        "            image, label = batch\n",
        "            image = image.to(device)\n",
        "\n",
        "            # Move label to the device before processing for loss\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Convert one-hot labels to class indices for CrossEntropyLoss, or keep as float for BCEWithLogitsLoss\n",
        "            if isinstance(loss_function, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(label, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = label.float()\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, labels_for_loss)\n",
        "\n",
        "            # Calculate predicted class indices\n",
        "            predicted_classes = torch.argmax(pred.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices\n",
        "            true_classes = torch.argmax(label, dim=1)\n",
        "\n",
        "            # Update metrics\n",
        "            f1_metric.update(predicted_classes, true_classes)\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            tq.update(1)\n",
        "\n",
        "    # Compute final metrics\n",
        "    val_f1score = f1_metric.compute()\n",
        "    val_accuracy = accuracy_metric.compute()\n",
        "\n",
        "    writer.add_scalar(\"Validation F1\", val_f1score, epoch)\n",
        "    writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
        "    writer.add_scalar(\"Validation Loss\", total_loss/len(data_val), epoch)\n",
        "\n",
        "    tq.close()\n",
        "    print(f\"F1 score: {val_f1score:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, run_name):\n",
        "    writer = SummaryWriter(log_dir=f'runs/{run_name}')\n",
        "\n",
        "    # Instantiate Accuracy for training\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        accuracy_metric.reset() # Reset accuracy for each epoch\n",
        "\n",
        "        tq = tqdm.tqdm(total=len(train_loader))\n",
        "        tq.set_description('epoch %d' % (epoch))\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device) # Move original labels to device first\n",
        "\n",
        "            if isinstance(loss_fn, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(labels, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = labels.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels_for_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
        "            tq.update(1)\n",
        "\n",
        "            # Calculate predicted class indices for training\n",
        "            predicted_classes = torch.argmax(outputs.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices for training\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            # Update the Accuracy metric\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "        # Compute final training accuracy\n",
        "        train_accuracy = accuracy_metric.compute()\n",
        "        writer.add_scalar(\"Training Loss\", running_loss/len(train_loader), epoch)\n",
        "        writer.add_scalar(\"Training Accuracy\", train_accuracy, epoch)\n",
        "\n",
        "        tq.close()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, n_epochs, epoch_loss, train_accuracy))\n",
        "\n",
        "        # Pass writer and epoch to val function\n",
        "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
        "\n",
        "        os.makedirs(save_model_path, exist_ok=True)\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Save the full model object after each epoch\n",
        "        torch.save(model, os.path.join(save_model_path, f\"full_{run_name}_epoch{epoch+1}_{pth_name}\"))\n",
        "        print(f\"Saved full model for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'full_{run_name}_epoch{epoch+1}_{pth_name}')}\")\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(save_model_path, f\"checkpoint_{run_name}_epoch{epoch+1}_{pth_name}\")) # Modified to save unique checkpoints per run_name\n",
        "        print(f\"saved the checkpoint for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'checkpoint_{run_name}_epoch{epoch+1}_{pth_name}')}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45f6ae4a"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError: name 'val_loader' is not defined` indicates that the `train_loader` and `val_loader` variables were not accessible within the scope of the previous code block, nor were their dependencies like `train_dataset`, `val_dataset`, and the `custom_dataset` class. To resolve this, I will regenerate the entire code block for Experiment 5, ensuring that all necessary imports, the `custom_dataset` class definition, the dataset and DataLoader instantiations for both training and validation, the `num_classes` definition, the `VGG16Model` class definition, and the `val` and `train` function definitions are all included and properly ordered before initiating the training process. This will make sure all variables and functions are defined and in scope when called.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44cde123"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import F1Score, Accuracy\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "save_model_path = \"checkpoints/\"\n",
        "pth_name = \"saved_model.pth\"\n",
        "\n",
        "# --- custom_dataset class definition ---\n",
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, mode = \"train\", root = \"datasets/demo_dataset\", transforms = None):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        #select split\n",
        "        self.folder = os.path.join(self.root, self.mode)\n",
        "\n",
        "        #initialize lists\n",
        "        self.image_list = []\n",
        "        self.label_list = []\n",
        "\n",
        "        #save class lists\n",
        "        self.class_list = os.listdir(self.folder)\n",
        "        self.class_list.sort()\n",
        "\n",
        "        for class_id in range(len(self.class_list)):\n",
        "            for image in os.listdir(os.path.join(self.folder, self.class_list[class_id])):\n",
        "                self.image_list.append(os.path.join(self.folder, self.class_list[class_id], image))\n",
        "                label = np.zeros(len(self.class_list))\n",
        "                label[class_id] = 1.0\n",
        "                self.label_list.append(label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.image_list[index]\n",
        "        label = self.label_list[index]\n",
        "\n",
        "\n",
        "        image = Image.open(image_name)\n",
        "        if(self.transforms):\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "# --- Data transformations ---\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')), # Ensure 3 channels\n",
        "    transforms.RandomResizedCrop(224), # Randomly crop and resize to 224x224\n",
        "    transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(15),     # Randomly rotate the image by a small degree\n",
        "    transforms.ToTensor(),             # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Lambda(lambda x: torch.cat([x, x, x], dim=0) if x.shape[0] == 1 else x), # Ensure 3 channels by concatenating if grayscale\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image pixel values\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert('RGB')), # Ensure 3 channels\n",
        "    transforms.Resize((224, 224)), # Resize images to 224x224\n",
        "    transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Lambda(lambda x: torch.cat([x, x, x], dim=0) if x.shape[0] == 1 else x), # Ensure 3 channels by concatenating if grayscale\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize image pixel values\n",
        "])\n",
        "\n",
        "# --- Data Root (assuming 'path' is defined from kagglehub.dataset_download) ---\n",
        "# The `path` variable is defined in cell 4020bffa as '/kaggle/input/astrophysical-objects-image-dataset'\n",
        "# actual_data_root was defined in cell 87ddfa51\n",
        "path = '/kaggle/input/astrophysical-objects-image-dataset'\n",
        "actual_data_root = os.path.join(path, 'astro_dataset_maxia', 'astro_dataset_maxia')\n",
        "\n",
        "# --- Dataset and DataLoader Instantiation ---\n",
        "train_dataset = custom_dataset(mode=\"training\", root=actual_data_root, transforms=train_transform)\n",
        "val_dataset = custom_dataset(mode=\"validation\", root=actual_data_root, transforms=val_transform)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
        "\n",
        "# Re-define num_classes to ensure it's accessible in this scope\n",
        "num_classes = len(train_dataset.class_list) # Dynamically get from dataset\n",
        "\n",
        "\n",
        "class VGG16Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use torchvision.models for VGG16, pass the pretrained argument\n",
        "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
        "\n",
        "        # Freeze all parameters in the feature extractor (convolutional layers) if pretrained\n",
        "        if pretrained:\n",
        "            for param in self.vgg16.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get the number of input features for the last classification layer\n",
        "        num_ftrs = self.vgg16.classifier[6].in_features\n",
        "\n",
        "        # Replace the last classification layer with a new one adapted to our num_classes\n",
        "        self.vgg16.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The VGG16 model already handles the forward pass through features and classifier\n",
        "        return self.vgg16(x)\n",
        "\n",
        "def val(model, data_val, loss_function, writer, epoch, device):\n",
        "    # Ensure F1Score and Accuracy are initialized with the correct num_classes and moved to device\n",
        "    f1_metric = F1Score(num_classes=num_classes, task='multiclass').to(device)\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    data_iterator = enumerate(data_val)  # take batches\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # switch model to evaluation mode\n",
        "        tq = tqdm.tqdm(total=len(data_val))\n",
        "        tq.set_description('Validation:')\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for _, batch in data_iterator:\n",
        "            # forward propagation\n",
        "            image, label = batch\n",
        "            image = image.to(device)\n",
        "\n",
        "            # Move label to the device before processing for loss\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Convert one-hot labels to class indices for CrossEntropyLoss, or keep as float for BCEWithLogitsLoss\n",
        "            if isinstance(loss_function, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(label, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = label.float()\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_function(pred, labels_for_loss)\n",
        "\n",
        "            # Calculate predicted class indices\n",
        "            predicted_classes = torch.argmax(pred.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices\n",
        "            true_classes = torch.argmax(label, dim=1)\n",
        "\n",
        "            # Update metrics\n",
        "            f1_metric.update(predicted_classes, true_classes)\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            tq.update(1)\n",
        "\n",
        "    # Compute final metrics\n",
        "    val_f1score = f1_metric.compute()\n",
        "    val_accuracy = accuracy_metric.compute()\n",
        "\n",
        "    writer.add_scalar(\"Validation F1\", val_f1score, epoch)\n",
        "    writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
        "    writer.add_scalar(\"Validation Loss\", total_loss/len(data_val), epoch)\n",
        "\n",
        "    tq.close()\n",
        "    print(f\"F1 score: {val_f1score:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device, run_name):\n",
        "    writer = SummaryWriter(log_dir=f'runs/{run_name}')\n",
        "\n",
        "    # Instantiate Accuracy for training\n",
        "    accuracy_metric = Accuracy(num_classes=num_classes, task='multiclass').to(device)\n",
        "\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        accuracy_metric.reset() # Reset accuracy for each epoch\n",
        "\n",
        "        tq = tqdm.tqdm(total=len(train_loader))\n",
        "        tq.set_description('epoch %d' % (epoch))\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device) # Move original labels to device first\n",
        "\n",
        "            if isinstance(loss_fn, nn.CrossEntropyLoss):\n",
        "                labels_for_loss = torch.argmax(labels, dim=1).long()\n",
        "            else:\n",
        "                labels_for_loss = labels.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels_for_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            tq.set_postfix(loss_st='%.6f' % loss.item())\n",
        "            tq.update(1)\n",
        "\n",
        "            # Calculate predicted class indices for training\n",
        "            predicted_classes = torch.argmax(outputs.softmax(dim=1), dim=1)\n",
        "            # Calculate true class indices for training\n",
        "            true_classes = torch.argmax(labels, dim=1)\n",
        "            # Update the Accuracy metric\n",
        "            accuracy_metric.update(predicted_classes, true_classes)\n",
        "\n",
        "        # Compute final training accuracy\n",
        "        train_accuracy = accuracy_metric.compute()\n",
        "        writer.add_scalar(\"Training Loss\", running_loss/len(train_loader), epoch)\n",
        "        writer.add_scalar(\"Training Accuracy\", train_accuracy, epoch)\n",
        "\n",
        "        tq.close()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, n_epochs, epoch_loss, train_accuracy))\n",
        "\n",
        "        # Pass writer and epoch to val function\n",
        "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
        "\n",
        "        os.makedirs(save_model_path, exist_ok=True)\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Save the full model object after each epoch\n",
        "        torch.save(model, os.path.join(save_model_path, f\"full_{run_name}_epoch{epoch+1}_{pth_name}\"))\n",
        "        print(f\"Saved full model for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'full_{run_name}_epoch{epoch+1}_{pth_name}')}\")\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(save_model_path, f\"checkpoint_{run_name}_epoch{epoch+1}_{pth_name}\")) # Modified to save unique checkpoints per run_name\n",
        "        print(f\"saved the checkpoint for {run_name} at epoch {epoch+1} to {os.path.join(save_model_path, f'checkpoint_{run_name}_epoch{epoch+1}_{pth_name}')}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_vgg16_pretrained_sgd = VGG16Model(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd_vgg16 = SGD(model_vgg16_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp5 = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 5: VGG16 (Pretrained) + SGD on {device} for {n_epochs_exp5} epochs...\")\n",
        "train(\n",
        "    model_vgg16_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd_vgg16,\n",
        "    loss_fn,\n",
        "    n_epochs_exp5,\n",
        "    device,\n",
        "    run_name='VGG16_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 5 complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b821a180"
      },
      "source": [
        "# Task\n",
        "Starting Experiment 5: VGG16 (Pretrained) + SGD on cpu for 15 epochs..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73629e8b"
      },
      "source": [
        "## Correct Device Assignment\n",
        "\n",
        "### Subtask:\n",
        "Modify the line `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")` to `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` to ensure a valid device is always selected. Then, re-instantiate the model and move it to the corrected device.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b20ec07"
      },
      "source": [
        "**Reasoning**:\n",
        "To fix the RuntimeError and ensure a valid device is always selected, I will modify the device assignment to use 'cpu' as a fallback, then re-instantiate the ExModel with the correct number of classes, and move the model to this newly defined device.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5babbc8d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Correct the device assignment\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Re-instantiate the model (using the updated ExModel from cell eb32e150)\n",
        "# Assuming num_classes is already defined from previous steps (it's 12)\n",
        "# And ExModel class is defined in the current context (from cell eb32e150)\n",
        "model = ExModel(num_classes=num_classes) # Default to pretrained=True as per previous usage\n",
        "\n",
        "# Move the model to the corrected device\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model instantiated and moved to {device}.\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37b676c7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully corrected the device assignment and instantiated the model. Now, I need to execute Experiment 1 as per the task, which involves instantiating `ExModel` (ResNet18) with pretrained weights, defining an SGD optimizer, and running the training process, logging its performance with a distinct run name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46119916"
      },
      "outputs": [],
      "source": [
        "model_resnet18_pretrained_sgd = ExModel(num_classes=num_classes, pretrained=True)\n",
        "optimizer_sgd = SGD(model_resnet18_pretrained_sgd.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_epochs_exp1 = 15 # Using the same number of epochs as the previous training run for consistency\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Starting Experiment 1: ResNet18 (Pretrained) + SGD on {device} for {n_epochs_exp1} epochs...\")\n",
        "train(\n",
        "    model_resnet18_pretrained_sgd,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_sgd,\n",
        "    loss_fn,\n",
        "    n_epochs_exp1,\n",
        "    device,\n",
        "    run_name='ResNet18_Pretrained_SGD'\n",
        ")\n",
        "print(\"Experiment 1 complete!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}